{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuhUMLGYEgEaHqlLqDWtbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivinSphere/Desempenho-de-Modelos-de-IA-com-Python/blob/main/Avalia%C3%A7%C3%A3o_de_Desempenho_de_Modelos_de_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--------Implementação rápida de avaliação de Desempenho de diversos modelos de Classificação----------**\n",
        "\n",
        "Todos os modelos listados são treinados e testados com o conjunto de treinamento disponível em fetch_openml(\"adult\")\n",
        "\n",
        "O dataframe final é ordenado pela Acurácia e então, pode-se observar os melhores modelos para os piores modelos nessas condições atuais e no conjunto de dados utilizados.\n",
        "\n",
        "\n",
        "**--------Informações Desenvolvedor----------**\n",
        "\n",
        "Código por Ismael Weslley Neves de Brito\n",
        "\n",
        "Linkedin: https://www.linkedin.com/in/ismael-weslley-a915b2236/\n",
        "\n",
        "Github: https://github.com/DivinSphere\n",
        "\n",
        "\n",
        "**--------Explicação da base de dados----------**\n",
        "\n",
        "A base de dados \"adult\" no OpenML é um conjunto de dados que contém informações sobre indivíduos adultos nos Estados Unidos, incluindo informações demográficas, educacionais e de renda. \n",
        "\n",
        "Ele é frequentemente usado como um exemplo de conjunto de dados para aprendizado supervisionado de classificação. \n",
        "\n",
        "A finalidade principal da base de dados é ser usado como um dataset para o treinamento e teste de algoritmos de machine learning.\n",
        "\n",
        "A variável de resultado é 'renda anual': '>50K' (favorável) ou '<=50K' (desfavorável).\n",
        "\n",
        "Dessa base de dados, 40 mil registros foram utilizados para o treinamento, para execuções mais rápidas, experimente diminuir o valor para 20 mil, 10 mil ou 5 mil.\n",
        "\n",
        "**--------Sobre os modelos utilizados----------**\n",
        "\n",
        "Os modelos foram escolhidos sem nenhum tipo de critério, alguns escolhidos apenas por serem muito conhecidos, outros nem tanto. Não houve algum critério de \"Esse modelo vai ser melhor para essa situação\" ou coisa do tipo, modelos aleatórios foram escolhidos para esse experimento.\n",
        "\n",
        "É importante notar que o desempenho de um modelo pode variar dependendo do conjunto de dados utilizado e das configurações específicas do modelo. Embora um modelo possa se sair melhor em um experimento específico, isso não significa necessariamente que ele será sempre superior a outros modelos.\n",
        "\n",
        "Além disso, os modelos utilizados neste código foram instanciados com suas configurações originais, sem a adição ou modificação de parâmetros para melhorar o desempenho. Isso é para garantir que os resultados sejam comparáveis entre os modelos e que as descobertas sejam baseadas nas configurações padrão dos algoritmos.\n",
        "\n",
        "Os valores e resultados dos modelos podem variar a cada vez que o código é executado, fazendo com que em determinado momento um algoritmo seja mais eficiente que outro, portanto é importante sempre verificar múltiplas vezes para ter certeza da eficácia do modelo."
      ],
      "metadata": {
        "id": "AuzsXK-QjkHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação de todas as bibliotecas necessárias para a execução correta do código\n",
        "# Adiciona todos os modelos de classificadores necessários\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (f1_score, accuracy_score, recall_score, precision_score, confusion_matrix, roc_auc_score, roc_curve)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import (LogisticRegression, Perceptron, RidgeClassifier, PassiveAggressiveClassifier, SGDClassifier)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYxPT4RwYf3V",
        "outputId": "6e751281-b153-4f3d-adc2-a4b0b8a4f457"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a função que vai retornar as estatisticas de cada modelo após executado\n",
        "def calculate_attributes(y_true, y_pred):\n",
        "    return {\n",
        "        # a acurácia é uma medida de quão precisos são os resultados do modelo, calculada dividindo o número de previsões corretas pelo número total de previsões.\n",
        "        \"acurácia\": accuracy_score(y_true, y_pred),\n",
        "        # O F1-score é uma média harmônica entre precisão e recall. Ele é útil quando a distribuição de classe é desbalanceada.\n",
        "        \"f1-score\": f1_score(y_true, y_pred, average='macro'),\n",
        "        # o recall é uma medida de quão completamente o modelo identifica as instâncias de uma classe específica, calculada dividindo o número de instâncias da classe específica identificadas corretamente pelo número total de instâncias da classe específica.\n",
        "        \"recall\": recall_score(y_true, y_pred, average='macro', zero_division=1),\n",
        "        # precisão é uma medida de quão frequentemente o modelo faz uma previsão correta para uma classe específica, calculada dividindo o número de previsões corretas para uma classe específica pelo número total de previsões para essa classe.\n",
        "        \"precisão\": precision_score(y_true, y_pred, average='macro', zero_division=1),\n",
        "        # A matriz de confusão é uma tabela que mostra as previsões corretas e incorretas do modelo para cada classe. Ele é útil para entender como o modelo está se comportando em relação a cada classe\n",
        "        \"matriz de confusão\": confusion_matrix(y_true, y_pred),\n",
        "        # ROC AUC é uma medida da capacidade do modelo de discriminar entre classes. Ele é calculado com base na curva ROC (receiver operating characteristic).\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_pred),\n",
        "        # A curva ROC é um gráfico que mostra a relação entre a taxa de verdadeiros positivos e a taxa de falsos positivos para diferentes limiares de classificação. Ela é útil para entender como o modelo se comporta em relação a diferentes níveis de sensibilidade e especificidade.\n",
        "        \"curva roc\": roc_curve(y_true, y_pred)\n",
        "    }"
      ],
      "metadata": {
        "id": "4cq9guzGqZO4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleção de todos os modelos que serão usados para se fazer a comparação das execuções e das estatisticas\n",
        "models = [\n",
        "    # Regressão Logística: é um algoritmo de classificação linear que é usado para prever a probabilidade de uma variável categórica dependente.\n",
        "    (\"Regressão Logística\", LogisticRegression()),\n",
        "    # Árvore de Decisão: é um algoritmo de aprendizado supervisionado que é usado para classificação e regressão. Ele funciona criando uma árvore de decisão com nós de decisão e folhas de classificação.\n",
        "    (\"Árvore de Decisão\", DecisionTreeClassifier()),\n",
        "    # K Vizinhos mais Próximos: é um algoritmo de aprendizado supervisionado baseado em instância que classifica novos exemplos baseando-se na maioria das classificações dos k vizinhos mais próximos.\n",
        "    (\"K Vizinhos mais Próximos\", KNeighborsClassifier()),\n",
        "    # Floresta Aleatória: é um conjunto de árvores de decisão, onde cada árvore é construída a partir de um subconjunto aleatório de exemplos e recursos do conjunto de dados.\n",
        "    (\"Floresta Aleatória\", RandomForestClassifier()),\n",
        "    # Gradient Boosting: é um algoritmo de aprendizado supervisionado que usa uma série de árvores de decisão para melhorar a precisão do modelo.\n",
        "    (\"Gradient Boosting\", GradientBoostingClassifier()),\n",
        "    # SVC: é uma classe de algoritmos de aprendizado de máquina supervisionado para classificação e regressão, baseado em algoritmos de classificação binária.\n",
        "    (\"SVC\", SVC()),\n",
        "    # Naive Bayes: é um conjunto de algoritmos de aprendizado supervisionado baseados na aplicação do teorema de Bayes com a suposição de independência entre os recursos.\n",
        "    (\"Naive Bayes\", GaussianNB()),\n",
        "    # Perceptron: é um algoritmo de aprendizado de máquina supervisionado usado para classificação binária.\n",
        "    (\"Perceptron\",Perceptron()),\n",
        "    # Rede Neural Multicamada: é um algoritmo de aprendizado de máquina supervisionado que consiste em várias camadas de nós de processamento.\n",
        "    (\"Rede Neural Multicamada\", MLPClassifier()),\n",
        "    # AdaBoost: é um algoritmo de aprendizado supervisionado que combina vários classificadores fracos para criar um classificador forte.\n",
        "    (\"AdaBoost\", AdaBoostClassifier()),\n",
        "    # Bagging: é um algoritmo de aprendizado supervisionado que consiste em aplicar o mesmo classificador várias vezes com subconjuntos aleatórios do conjunto de dados.\n",
        "    (\"Bagging\", BaggingClassifier()),\n",
        "    # ExtraTreesClassifier: é uma variação do algoritmo Random Forest, onde cada árvore é construída a partir de um subconjunto aleatório de exemplos e recursos do conjunto de dados e todos os recursos são considerados em cada divisão.\n",
        "    (\"ExtraTreesClassifier\", ExtraTreesClassifier()),\n",
        "    # XGBoost: é uma biblioteca de aprendizado de máquina de código aberto que implementa o algoritmo de gradient boosting de árvore de decisão.\n",
        "    (\"XGBoost\", XGBClassifier()),\n",
        "    # LightGBM: é uma biblioteca de aprendizado de máquina de código aberto que implementa o algoritmo de gradient boosting de árvore de decisão otimizado para grandes conjuntos de dados.\n",
        "    (\"LightGBM\", LGBMClassifier()),\n",
        "    # Ridge: é um algoritmo de classificação linear que é usado para prever a probabilidade de uma variável categórica dependente, ele inclui uma regularização L2.\n",
        "    (\"Ridge\", RidgeClassifier()),\n",
        "    # PassiveAggressiveClassifier: é um algoritmo de aprendizado supervisionado baseado em instância que atualiza o modelo de acordo com os erros cometidos.\n",
        "    (\"PassiveAggressiveClassifier\", PassiveAggressiveClassifier()),\n",
        "    # SGDClassifier: é uma classe de algoritmos de aprendizado de máquina supervisionado para classificação e regressão, baseado em algoritmos de descida de gradiente estocástico.\n",
        "    (\"SGDClassifier\",SGDClassifier()),\n",
        "    # BernoulliNB: é um algoritmo de classificação baseado em Bayes, específico para dados binários. Ele assume que todas as características são binárias e aplica o teorema de Bayes com a suposição de independência entre os recursos.\n",
        "    (\"BernoulliNB\",BernoulliNB()),\n",
        "    # HistGradientBoostingClassifier: é uma variação do algoritmo Gradient Boosting que usa técnicas de histograma para otimizar a construção das árvores. \n",
        "    (\"HistGradientBoostingClassifier\",HistGradientBoostingClassifier()),\n",
        "    # DummyClassifier: é um classificador \"dummy\" que permite definir uma estratégia para atribuir classes aos exemplos. Ele pode ser usado como uma base de comparação para outros classificadores.\n",
        "    (\"DummyClassifier\",DummyClassifier()),\n",
        "    # MultinomialNB: é uma variação do algoritmo Naive Bayes, específico para dados contínuos. Ele assume que todas as características são contínuas e aplica o teorema de Bayes com a suposição de independência entre os recursos.\n",
        "    (\"MultinomialNB\",MultinomialNB())\n",
        "]"
      ],
      "metadata": {
        "id": "96aEJ2aEqaRp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando o dataset com uma amostra de valores\n",
        "data = fetch_openml(\"adult\",version=1)\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df = df.sample(n=40000)\n",
        "data.target = data.target[df.index]\n",
        "\n",
        "# tratando as variaveis categóricas\n",
        "df = pd.get_dummies(df, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
        "\n",
        "# separando em treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "X_train = X_train.astype(np.float64)\n",
        "X_test = X_test.astype(np.float64)"
      ],
      "metadata": {
        "id": "BBvQNMRQYAee"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treina cada modelo com os dados\n",
        "# Retorna suas estatisticas para cada execução\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[name] = calculate_attributes(y_test, y_pred)\n",
        "\n",
        "# Transforma em um DataFrame Pandas\n",
        "# Retorna com os modelos organizados por ordem de Acurácia\n",
        "df_modelos = pd.DataFrame.from_dict(results).T\n",
        "df_modelos = df_modelos.sort_values(\"acurácia\", ascending=False)\n",
        "df_modelos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "ffFYMQaPTOdD",
        "outputId": "dd92a024-4398-418c-cfb4-738674dfc678"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                acurácia  f1-score    recall  precisão  \\\n",
              "LightGBM                        0.855875  0.791845  0.776329   0.81312   \n",
              "HistGradientBoostingClassifier   0.85575  0.791539  0.775895  0.813059   \n",
              "Gradient Boosting                0.85375   0.78526   0.76632  0.813614   \n",
              "XGBoost                            0.853  0.783168  0.763366  0.813547   \n",
              "AdaBoost                        0.851125  0.784118  0.768101  0.806618   \n",
              "Ridge                           0.844625  0.761496  0.735882  0.810409   \n",
              "Floresta Aleatória              0.828125  0.758614  0.751171  0.767501   \n",
              "Bagging                         0.826375  0.750038  0.737544  0.767219   \n",
              "ExtraTreesClassifier            0.816125  0.745002  0.740794  0.749687   \n",
              "Árvore de Decisão                 0.7965  0.725247   0.72732  0.723292   \n",
              "MultinomialNB                   0.788875  0.736414  0.761287  0.723461   \n",
              "Rede Neural Multicamada         0.772375  0.579115  0.576143    0.6893   \n",
              "Perceptron                      0.757875  0.431131       0.5  0.878937   \n",
              "Naive Bayes                     0.757875  0.431131       0.5  0.878937   \n",
              "SVC                             0.757875  0.431131       0.5  0.878937   \n",
              "PassiveAggressiveClassifier     0.757875  0.431131       0.5  0.878937   \n",
              "SGDClassifier                   0.757875  0.431131       0.5  0.878937   \n",
              "DummyClassifier                 0.757875  0.431131       0.5  0.878937   \n",
              "Regressão Logística             0.757875  0.431131       0.5  0.878937   \n",
              "BernoulliNB                       0.7535  0.714707   0.76746  0.706469   \n",
              "K Vizinhos mais Próximos         0.72325  0.534771  0.538112  0.565579   \n",
              "\n",
              "                                         matriz de confusão   roc_auc  \\\n",
              "LightGBM                         [[5642, 421], [732, 1205]]  0.776329   \n",
              "HistGradientBoostingClassifier   [[5643, 420], [734, 1203]]  0.775895   \n",
              "Gradient Boosting                [[5674, 389], [781, 1156]]   0.76632   \n",
              "XGBoost                          [[5682, 381], [795, 1142]]  0.763366   \n",
              "AdaBoost                         [[5633, 430], [761, 1176]]  0.768101   \n",
              "Ridge                            [[5740, 323], [920, 1017]]  0.735882   \n",
              "Floresta Aleatória               [[5459, 604], [771, 1166]]  0.751171   \n",
              "Bagging                          [[5516, 547], [842, 1095]]  0.737544   \n",
              "ExtraTreesClassifier             [[5377, 686], [785, 1152]]  0.740794   \n",
              "Árvore de Decisão                [[5223, 840], [788, 1149]]   0.72732   \n",
              "MultinomialNB                   [[4940, 1123], [566, 1371]]  0.761287   \n",
              "Rede Neural Multicamada          [[5800, 263], [1558, 379]]  0.576143   \n",
              "Perceptron                           [[6063, 0], [1937, 0]]       0.5   \n",
              "Naive Bayes                          [[6063, 0], [1937, 0]]       0.5   \n",
              "SVC                                  [[6063, 0], [1937, 0]]       0.5   \n",
              "PassiveAggressiveClassifier          [[6063, 0], [1937, 0]]       0.5   \n",
              "SGDClassifier                        [[6063, 0], [1937, 0]]       0.5   \n",
              "DummyClassifier                      [[6063, 0], [1937, 0]]       0.5   \n",
              "Regressão Logística                  [[6063, 0], [1937, 0]]       0.5   \n",
              "BernoulliNB                     [[4489, 1574], [398, 1539]]   0.76746   \n",
              "K Vizinhos mais Próximos         [[5439, 624], [1590, 347]]  0.538112   \n",
              "\n",
              "                                                                        curva roc  \n",
              "LightGBM                        ([0.0, 0.0694375721589972, 1.0], [0.0, 0.62209...  \n",
              "HistGradientBoostingClassifier  ([0.0, 0.06927263730826323, 1.0], [0.0, 0.6210...  \n",
              "Gradient Boosting               ([0.0, 0.06415965693551047, 1.0], [0.0, 0.5967...  \n",
              "XGBoost                         ([0.0, 0.0628401781296388, 1.0], [0.0, 0.58957...  \n",
              "AdaBoost                        ([0.0, 0.07092198581560284, 1.0], [0.0, 0.6071...  \n",
              "Ridge                           ([0.0, 0.05327395678706911, 1.0], [0.0, 0.5250...  \n",
              "Floresta Aleatória              ([0.0, 0.0996206498433119, 1.0], [0.0, 0.60196...  \n",
              "Bagging                         ([0.0, 0.09021936335147616, 1.0], [0.0, 0.5653...  \n",
              "ExtraTreesClassifier            ([0.0, 0.11314530760349661, 1.0], [0.0, 0.5947...  \n",
              "Árvore de Decisão               ([0.0, 0.13854527461652646, 1.0], [0.0, 0.5931...  \n",
              "MultinomialNB                   ([0.0, 0.18522183737423717, 1.0], [0.0, 0.7077...  \n",
              "Rede Neural Multicamada         ([0.0, 0.043377865743031506, 1.0], [0.0, 0.195...  \n",
              "Perceptron                                       ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "Naive Bayes                                      ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "SVC                                              ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "PassiveAggressiveClassifier                      ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "SGDClassifier                                    ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "DummyClassifier                                  ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "Regressão Logística                              ([0.0, 1.0], [0.0, 1.0], [1, 0])  \n",
              "BernoulliNB                     ([0.0, 0.2596074550552532, 1.0], [0.0, 0.79452...  \n",
              "K Vizinhos mais Próximos        ([0.0, 0.10291934685799109, 1.0], [0.0, 0.1791...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fc73e69-c734-4b8c-89e0-10c3f45ce8b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acurácia</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>recall</th>\n",
              "      <th>precisão</th>\n",
              "      <th>matriz de confusão</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>curva roc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.855875</td>\n",
              "      <td>0.791845</td>\n",
              "      <td>0.776329</td>\n",
              "      <td>0.81312</td>\n",
              "      <td>[[5642, 421], [732, 1205]]</td>\n",
              "      <td>0.776329</td>\n",
              "      <td>([0.0, 0.0694375721589972, 1.0], [0.0, 0.62209...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HistGradientBoostingClassifier</th>\n",
              "      <td>0.85575</td>\n",
              "      <td>0.791539</td>\n",
              "      <td>0.775895</td>\n",
              "      <td>0.813059</td>\n",
              "      <td>[[5643, 420], [734, 1203]]</td>\n",
              "      <td>0.775895</td>\n",
              "      <td>([0.0, 0.06927263730826323, 1.0], [0.0, 0.6210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <td>0.85375</td>\n",
              "      <td>0.78526</td>\n",
              "      <td>0.76632</td>\n",
              "      <td>0.813614</td>\n",
              "      <td>[[5674, 389], [781, 1156]]</td>\n",
              "      <td>0.76632</td>\n",
              "      <td>([0.0, 0.06415965693551047, 1.0], [0.0, 0.5967...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.783168</td>\n",
              "      <td>0.763366</td>\n",
              "      <td>0.813547</td>\n",
              "      <td>[[5682, 381], [795, 1142]]</td>\n",
              "      <td>0.763366</td>\n",
              "      <td>([0.0, 0.0628401781296388, 1.0], [0.0, 0.58957...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.851125</td>\n",
              "      <td>0.784118</td>\n",
              "      <td>0.768101</td>\n",
              "      <td>0.806618</td>\n",
              "      <td>[[5633, 430], [761, 1176]]</td>\n",
              "      <td>0.768101</td>\n",
              "      <td>([0.0, 0.07092198581560284, 1.0], [0.0, 0.6071...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.844625</td>\n",
              "      <td>0.761496</td>\n",
              "      <td>0.735882</td>\n",
              "      <td>0.810409</td>\n",
              "      <td>[[5740, 323], [920, 1017]]</td>\n",
              "      <td>0.735882</td>\n",
              "      <td>([0.0, 0.05327395678706911, 1.0], [0.0, 0.5250...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Floresta Aleatória</th>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.758614</td>\n",
              "      <td>0.751171</td>\n",
              "      <td>0.767501</td>\n",
              "      <td>[[5459, 604], [771, 1166]]</td>\n",
              "      <td>0.751171</td>\n",
              "      <td>([0.0, 0.0996206498433119, 1.0], [0.0, 0.60196...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.826375</td>\n",
              "      <td>0.750038</td>\n",
              "      <td>0.737544</td>\n",
              "      <td>0.767219</td>\n",
              "      <td>[[5516, 547], [842, 1095]]</td>\n",
              "      <td>0.737544</td>\n",
              "      <td>([0.0, 0.09021936335147616, 1.0], [0.0, 0.5653...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.816125</td>\n",
              "      <td>0.745002</td>\n",
              "      <td>0.740794</td>\n",
              "      <td>0.749687</td>\n",
              "      <td>[[5377, 686], [785, 1152]]</td>\n",
              "      <td>0.740794</td>\n",
              "      <td>([0.0, 0.11314530760349661, 1.0], [0.0, 0.5947...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Árvore de Decisão</th>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.725247</td>\n",
              "      <td>0.72732</td>\n",
              "      <td>0.723292</td>\n",
              "      <td>[[5223, 840], [788, 1149]]</td>\n",
              "      <td>0.72732</td>\n",
              "      <td>([0.0, 0.13854527461652646, 1.0], [0.0, 0.5931...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.788875</td>\n",
              "      <td>0.736414</td>\n",
              "      <td>0.761287</td>\n",
              "      <td>0.723461</td>\n",
              "      <td>[[4940, 1123], [566, 1371]]</td>\n",
              "      <td>0.761287</td>\n",
              "      <td>([0.0, 0.18522183737423717, 1.0], [0.0, 0.7077...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rede Neural Multicamada</th>\n",
              "      <td>0.772375</td>\n",
              "      <td>0.579115</td>\n",
              "      <td>0.576143</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>[[5800, 263], [1558, 379]]</td>\n",
              "      <td>0.576143</td>\n",
              "      <td>([0.0, 0.043377865743031506, 1.0], [0.0, 0.195...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Regressão Logística</th>\n",
              "      <td>0.757875</td>\n",
              "      <td>0.431131</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.878937</td>\n",
              "      <td>[[6063, 0], [1937, 0]]</td>\n",
              "      <td>0.5</td>\n",
              "      <td>([0.0, 1.0], [0.0, 1.0], [1, 0])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.7535</td>\n",
              "      <td>0.714707</td>\n",
              "      <td>0.76746</td>\n",
              "      <td>0.706469</td>\n",
              "      <td>[[4489, 1574], [398, 1539]]</td>\n",
              "      <td>0.76746</td>\n",
              "      <td>([0.0, 0.2596074550552532, 1.0], [0.0, 0.79452...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K Vizinhos mais Próximos</th>\n",
              "      <td>0.72325</td>\n",
              "      <td>0.534771</td>\n",
              "      <td>0.538112</td>\n",
              "      <td>0.565579</td>\n",
              "      <td>[[5439, 624], [1590, 347]]</td>\n",
              "      <td>0.538112</td>\n",
              "      <td>([0.0, 0.10291934685799109, 1.0], [0.0, 0.1791...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fc73e69-c734-4b8c-89e0-10c3f45ce8b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9fc73e69-c734-4b8c-89e0-10c3f45ce8b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9fc73e69-c734-4b8c-89e0-10c3f45ce8b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}